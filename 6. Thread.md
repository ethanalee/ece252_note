# Thread

[TOC]



## Thread

### Thread

**Thread**: a short form of *Thread of Execution*.

a sequence of executable commands that can be scheduled to run on the CPU. 

have some state (where in the sequence of executable commands the program is) and some local variables. 

- **pthread_create** – Create a new thread. This works a lot like fork.
- **pthread_exit** – Terminate the calling thread. This is like exit in that it ends execution and returns a value.
- **pthread_join** – Wait for a specific thread to exit. This is like wait: the caller cannot proceed until the thread it is waiting for calls pthread_exit. Note that it is an error to join a thread that has already been joined.
- **pthread_detach**–If we want to make it so that a thread cannot be joined, then we can make it a “detached” thread with this function.
- **pthread_yield** – Release the CPU and let another thread run. As they all belong to the same program, we expect that threads want to co-operate rather then compete for CPU time and threads can make decisions about when it would be ideal to let some other thread run instead. 

### Multi-Thread

A multithreaded program is one that uses more than one thread, at least some of the time. 

When a program is started, it begins with an initial thread (where the main function is) and that <u>**main thread** can create some additional threads if needed</u>. 

Note that threads can be created and destroyed within a program <u>dynamically</u>: a thread can be created to handle a specific background task, like writing changes to the database, and will terminate when it is done. Or a created thread might be persistent.

In a process that has multiple threads, each thread has its own:

1. Thread execution state (like process state: running, ready, blocked...). 
2. Saved thread context when not running.
3. Execution stack.
4. Local variables.

5. Access to the memory and resources of the process (shared with all threads in that process).

![page1image104641744.png](/Users/shuyi/Library/Application Support/typora-user-images/page1image104641744.png) 

All the threads of a process share the state and resources of the process. If one thread opens a file, other threads in that process can also access that file.

### Create Thread and collect return value

#### pthread_create()

Create a new thread. This works a lot like fork. 

```c
pthread_create( pthread_t *thread, const pthread_attr_t * attr, void *(*start_routine)( void * ), void *arg );

void* function( void * start_params ) {
	parameters_t *arguments = (parameters_t*) start_params; 
  /* continue after this */
}
```

#### pthread_exit()

Terminate the calling thread. This is like exit in that it ends execution and returns a value. 

```c
void pthread_exit(void *retval);
```

If a thread has no return values, it can just return `NULL`;

which will have the same effect aspthread_exit and send `NULL` back to the thread that has joined it.

#### pthread_join()

Wait for a specific thread to exit. This is like wait: the caller cannot proceed until the thread it is waiting for calls pthread_exit. Note that it is an error to join a thread that has already been joined. 

```c
pthread_join( pthread_t thread, void** retval );
```

##### example: Collecting Returned Values.

```c
#include <stdlib.h> 
#include <stdio.h> 
#include <pthread.h>

void * run( void * argument ) {
	char* a = (char*) argument; 
	printf("Provided argument is %s!\n", a); 
	int * return_val = malloc( sizeof( int )); 
	*return_val = 99;
	pthread_exit( return_val );
}

int main( int argc, char** argv ) { 
	if (argc != 2) {
  	printf("Invalid args.\n");
		return -1; 
  }
  pthread_t t; 
  void* vr;
  pthread_create( &t, NULL, run, argv[1] ); 
  pthread_join( t, &vr );
  int* r = (int*) vr;
  printf("The other thread returned %d.\n", *r); 
  free( vr );
  pthread_exit( 0 );
}
```

#### pthread_attr

attributes can be used to set whether a thread is detached or joinable, scheduling pol- icy, etc. 

```c
int pthread_attr_init(pthread_attr_t *attr);
int pthread_attr_destroy(pthread_attr_t *attr);
```

- `pthread_attr_init` – Create and initialize a thread’s attributes. The attributes contain things like the priority of the thread. (“After you, sir.” “Oh no, after you.”) 
- `pthread_attr_destroy` – Remove a thread’s attributes. Free up the memory holding the thread’s attributes. This does not terminate the threads. 

##### example : how to initialize and the attributes

```c
#include <pthread.h> 
#include <stdio.h>
int sum; /* Shared Data */
void *runner(void *param);

int main( int argc, char **argv ) {
  pthread_t tid; /* the thread identifier */
  pthread_attr_t attr; /* set of thread attributes */
  if ( argc != 2 ) {
  	fprintf(stderr,"usage: %s <integer value>\n", argv[0]); 
    return -1;
  }
  if ( atoi( argv[1] ) < 0 ) {
    fprintf(stderr, "%d must be >= 0\n", atoi(argv[1]));
  	return -1; 
  }
  /* set the default attributes */
  pthread_attr_init( &attr );
  /* create the thread */
  pthread_create( &tid, &attr, runner, argv[1] );
  pthread_join( tid, NULL );
  printf( "sum = %d\n", sum );
  pthread_exit( NULL );
}
void *runner( void *param ) {
  int upper = atoi( param );
  sum = 0;
  for ( int i = 1; i <= upper; i++ ) {
  	sum += i; 
  }
  pthread_exit( 0 );
}

```

In this example, both threads are sharing the global variable sum. We have some form of co-ordination here because the parent thread will join the newly-spawned thread (i.e., wait until it is finished) before it tries to print out the value. If it did not join the spawned thread, the parent thread would print out the sum early.

#### pthread_detach () + pthread_yield()

- `pthread_detach`–If we want to make it so that a thread cannot be joined, then we can make it a “detached” thread with this function. 
- `pthread_yield` – Release the CPU and let another thread run. As they all belong to the same program, we expect that threads want to co-operate rather then compete for CPU time and threads can make decisions about when it would be ideal to let some other thread run instead. 



### Cancel a thread

#### pthread_setcanceltype()

A thread can declare its own cancellation type.

The thread that we are going to cancel is called the *target* and there are two ways a thread might get cancelled :

1. **Asynchronous Cancellation:** One thread immediately terminates the target.
2. **Deferred Cancellation:** The target is informed that it is cancelled; the target is responsible for checking regularly if it is terminated, allowing it to clean itself up properly.

```c
pthread_setcanceltype( int type, int *oldtype )
```

- argument:
  - **type**: 
    - **PTHREAD_CANCEL_DEFERRED**
    - **PTHREAD_CANCEL_ASYNCHRONOUS**
  - **oldtype**: be updated to point to what the previous state was

#### pthread_cancel()

Signal cancellation to a thread; this can be asynchronous or deferred, depending on the thread’s attributes. 

```c
int pthread_cancel(pthread_t thread);
```



#### pthread_testcancel()

A thread can check to see if it has been cancelled. If that is the case, this function terminates the calling thread. 

```c
void pthread_testcancel(void);
```

It is good programming practice to check `pthread_testcancel` at the start or end of each iteration of the loop, and if cancellation has been signalled, clean up open files and network connections, and then `pthread_exit`. 

#### pthread_cleanup_push()

register a cleanup handler that deallocates that memory in case the thread should die unceremoniously.

```c
pthread_cleanup_push( void (*routine)(void*), void *argument ); /* Register cleanup handler, with argument */
```

- argument: 
  - **routine**: the function that is supposed to run
  - **argument**: a pointer to the argument that cleanup function will need

#### pthread_cleanup_pop()

The push function always needs to be paired with the pop function at the same level in your program (where level is defined by the curly braces). 

```c
pthread_cleanup_pop( int execute ); /* Run if execute is non-zero */
```

The pop function takes one argument: whether it should run or not. 

If the thread is cancelled, the cleanup function will run; 

if it continues to the pop function, then you get to choose whether it runs or not.

##### example : dont run clean up function 

```c
void cleanup( void* mem ) { 
	free( mem );
}
void* do_work( void* argument ) {
  struct job * j = malloc( sizeof( struct job ) ); 
  pthread_cleanup_push( cleanup, j );
  /* Do something useful with this structure */
  /* Actual work to do not shown */
  free( j );
  pthread_cleanup_pop( 0 ); /* Don’t run */ 
  pthread_exit( NULL );
}
```

## Concurrency

### Parallelism and Speedup

If a task can be partially parallelized, it means the task can be divided, but doubling the workers doesn’t result in completing the job in half the time. Two chefs working together in a kitchen might take 75% of the time it would take one chef to cook a meal. Adding the extra worker to the kitchen improved the speed at which food was prepared, but it’s not doubled. The chefs can work independently some of the time, but at other times one has to wait for the other; the sauce cannot be put on the chicken until the chicken comes out of the oven.

If a task cannot be parallelized at all, then no amount of extra workers will speed it up. Some tasks can only be done sequentially. You can’t cook the steak in one minute by putting it in five ovens (this makes the chef very mad).

#### Amdahl’s Law

![image-20191217021126687](/Users/shuyi/Library/Application Support/typora-user-images/image-20191217021126687.png)

Let us define S as the portion of the application that must be performed serially and N as the number of processing cores available.

### Synchronization

**Serialization**: some sort of order of events.

- e.g. Certainty that Event *A* takes place before Event *B*.

**critical section**: A section of code that should be accessed by a maximum of one thread at a time

**Mutual exclusion**: events *C* and *D* must not happen at the same time.

- e.g. If we have mutual exclusion, we are certain that *P*1 writing to the shared area (event *C*) does not happen at the same time as *P*2 tries to read it (event *D*).
- ensure that at most one thread is in the critical section at a time.

**atomic**: indivisible (cannot be separated)

### semaphore

**binary semaphore**: this is a variable that has two values, 0 and 1.

The semaphore has two operations: `wait` and `post`.

#### semaphore functions

```c
sem_init( sem_t* semaphore , int shared , int initial_value );
sem_destroy ( sem_t* semaphore )
sem_wait ( sem_t*semaphore ) 
sem_post (sem_t* semaphore )
```



#### Wait()

The `wait` operation on the semaphore is how a program tries to enter the critical section.

When `wait` is called, if the semaphore value is 1, set it to 0 and this thread may enter the critical section and continue.

If the semaphore is 0, some other thread is in the critical section and the current thread must `wait` its turn.

#### post() or signal()

The post (or signal) operation is how a program *signals*, or indicates, it is finished with the critical section.

When this is called, if the semaphore is 1, do nothing.

If the semaphore is 0 and there is a task blocked awaiting that semaphore, that task may be unblocked.

#### example: semaphore solution for linked list

```c
typedef struct single_node { 
  void *element;
	struct single_node *next;
} single_node_t;
typedef struct single_list { 
  single_node_t *head;
  single_node_t *tail;
	int size;
  sem_t sem;
} single_list_t;
void single_list_init( single_list_t *list ) { 
  list->head = NULL;
	list->tail = NULL;
	list->size = 0;
  sem_init( &( list->sem ), 0, 1 );
}
bool push_front( single_list_t *list, void *obj ) { 
  single_node_t *tmp = malloc( sizeof( single_node_t ) );
	if ( tmp == NULL ) { 
    return false;
	}
  tmp->element = obj;
  
  sem_wait( &( list->sem ) ); 
  {
    tmp->next = list->head;
    list->head = tmp;
    if ( list->size == 0 ) { 
      list->tail = tmp;
    }
    ++( list->size );
  } 
  sem_post( &( list->sem ) );
	return true; 
}

```

### Mutex

A data structure called a `mutex` is a binary semaphore with an additional rule enforced: only the thread that has called `wait` may `post` that semaphore.

Although typically when we have a `mutex` we use the terms lock and unlock.

**Thread A**

```
1. wait( mutex ) or lock
2. critical section 
3. post( mutex ) or unlock
```

**Thread B**

```
1. wait( mutex ) or lock
2. critical section
3. post( mutex ) or unlock
```

The mutex semaphore is originally initialized to 1.

Whichever thread gets to the wait statement first will proceed immediately and not be blocked at all.



```c
pthread_mutex_init( pthread_mutex_t *mutex, pthread_mutexattr_t *attributes ) ;
pthread_mutex_lock( pthread_mutex_t *mutex );
pthread_mutex_trylock( pthread_mutex_t *mutex ); /* Returns 0 on success */ 
pthread_mutex_unlock( pthread_mutex_t *mutex );
pthread_mutex_destroy( pthread_mutex_t *mutex );
```



### Multiplex

If the general semaphore is initialized to *n*, then at most *n* threads can be in the critical section at a time.

In a computer related example, suppose that the system has a problem that when too many concurrent database requests are happening. The queries become slow and eventually time out. A potential solution is to protect all database accesses with a binary semaphore, so only one database query can run at any time. Analysis may reveal that this is too restrictive a policy; perhaps we can execute 5 queries concurrently without any slowdown. Then initialize the semaphore with a value of 5, allowing at most 5 threads into the critical section at any time.

**Thread K**

```
1. wait( mutex )
2. critical section
3. post( mutex )
```

### Condition Variables

#### condition variable functions

```c
// initialize a pthread_cond_t
pthread_cond_init( pthread_cond_t *cv, pthread_condattr_t *attributes ); 

// should be called only while the mutex is locked
// automatically release the mutex while it waits for the condition
// when the condition is true then the mutex will be automatically locked again so the thread may proceed
// The programmer then unlocks the mutex when the thread is finished with it 
pthread_cond_wait( pthread_cond_t *cv, pthread_mutex_t *mutex ); 

//signals a provided condition variable,
pthread_cond_signal( pthread_cond_t *cv );

//signals all threads waiting on that condition variable
pthread_cond_broadcast( pthread_cond_t *cv );

//to destroy them
pthread_cond_destroy( pthread_cond_t *cv );

```

#### example: use conditional variable 

```c
#include <pthread.h> 
#include <stdio.h> 
#include <stdlib.h>
#define NUM_THREADS 3 
#define COUNT_LIMIT 12
int count = 0;
pthread_mutex_t count_mutex; 
pthread_cond_t count_threshold_cv;
void* inc_count( void* arg ) { 
	for (int i = 0; i < 10; i++ ) {
    pthread_mutex_lock( &count_mutex );
    count++;
    if ( count == COUNT_LIMIT ) {
      printf( "Condition Fulfilled!\n" ); 
      pthread_cond_signal( &count_threshold_cv ); 
      printf( "Sent signal.\n" );
  	}
    pthread_mutex_unlock( &count_mutex );
  }
  pthread_exit( NULL );
}

void* watch_count( void *arg ) { 
	pthread_mutex_lock( &count_mutex ); 
	if ( count < COUNT_LIMIT ) {
		pthread_cond_wait( &count_threshold_cv, &count_mutex );
		printf( "Watcher has woken up.\n" );
		/* Do something useful here now that condition is fulfilled. */
  }
  pthread_mutex_unlock( &count_mutex );
  pthread_exit( NULL );
}

int main( int argc, char **argv ) { 
  pthread_t threads[3];
  
  pthread_mutex_init( &count_mutex, NULL );
  pthread_cond_init ( &count_threshold_cv, NULL );

  pthread_create( &threads[0], NULL, watch_count, NULL ); 
  pthread_create( &threads[1], NULL, inc_count, NULL ); 
  pthread_create( &threads[2], NULL, inc_count, NULL );
  
  for ( int i = 0; i < NUM_THREADS; i++ ) { 
    pthread_join(threads[i], NULL);
  }
  
  pthread_mutex_destroy( &count_mutex ); 
  pthread_cond_destroy( &count_threshold_cv ); 
  pthread_exit( NULL );
}

```

#### example: use broadcast for single barrier

```c
int count; 
pthread_mutex_t lock; 
pthread_cond_t cv;

void barrier( ) { 
  pthread_mutex_lock( &lock ); 
  count++;
  if ( count < NUM_THREADS ) {
    pthread_cond_wait( &cv, &lock ); 
  } else {
    pthread_cond_broadcast( &cv );
  }
  pthread_mutex_unlock( &lock );
}
```

#### example: monitor

A condition variable can be used to create a monitor, a higher level synchronization construct.

Only one thread can be inside that method at a time

```c
void foo( ) { 
	pthread_mutex_lock( &l ); /* Read some data */
	if ( condition ) {
    printf( "Cannot continue due to reasons...\n" );
		return; 
	}
  /* More stuff */
  pthread_mutex_unlock( &l );
}
```

### Atomic Types

```c
//used to assign a new value, and returns the old value
type __sync_lock_test_and_set( type *ptr, type value );

//used to swap two values, only if the old value matches the expected
bool __sync_bool_compare_and_swap( type *ptr, type oldval, type newval ); type __sync_val_compare_and_swap( type *ptr, type oldval, type newval );

//perform the operation and return the old value
type __sync_fetch_and_add( type *ptr, type value );
type __sync_fetch_and_sub( type *ptr, type value );
type __sync_fetch_and_or( type *ptr, type value );
type __sync_fetch_and_and( type *ptr, type value );
type __sync_fetch_and_xor( type *ptr, type value );
type __sync_fetch_and_nand( type *ptr, type value );

//perform the operation and return the new value
type __sync_add_and_fetch( type *ptr, type value );
type __sync_sub_and_fetch( type *ptr, type value );
type __sync_or_and_fetch( type *ptr, type value );
type __sync_and_and_fetch( type *ptr, type value );
type __sync_xor_and_fetch( type *ptr, type value );
type __sync_nand_and_fetch( type *ptr, type value );
```

Interestingly, for x86 there is no atomic read operation. 

The (normal) read itself is atomic for 32-bit-aligned data. 

This behaviour is specific to x86 and we have mostly tried to avoid relying on anything that is implementation- specific behaviour... If we do rely on this, however, we could get an out-of-date value.

### spinlock

This is a handy way to implement constant checking to acquire a lock. Unlike semaphores where the process is blocked if it fails to acquire the lock, a thread will constantly try to acquire the lock.

```c
spin_lock( &lock )
    /* Critical Section */
spin_unlock( &lock )
```

The implementation is an integer that is checked by a thread; if the value is 0, the thread can lock it (set the value to 1) and continue; if it is nonzero, it constantly checks the value until the value becomes 0. 

#### reader-writer-spinlocks

| **Counter** | **Flag** | **Interpretation**                                        |
| ----------- | -------- | --------------------------------------------------------- |
| 0           | 1        | The spinlock is released and available.                   |
| 0           | 0        | The spinlock has been acquired for writing.               |
| n           | 0        | The spin lock has been acquired for reading by n threads. |
| n           | 1        | Invalid state.                                            |



## Synchronization Patterns

### Signalling

**Thread A**

```
1. Statement A1
2. post( sem )
```

**Thread B**

```
1. wait( sem ) 
2. Statement B2
```

- statement A1 run before statement B2 regardless

### Rendezvous

Two threads should be at the same point before either of them may proceed (they “meet up”).

#### Rendezvous Solution 1 (not working)

**Thread A**

```
1. Statement A1
2. wait( bArrived )
3. post( aArrived )
4. Statement A2
```

**Thread B**

```
1. Statement B1
2. wait( aArrived )
3. post( bArrived )
4. Statement B2
```

there is a deadlock, when both thread are waiting 

#### Rendezvous Solution 2 (working)

**Thread A**

```
1. Statement A1
2. post( aArrived )
3. wait( bArrived )
4. Statement A2
```

**Thread B**

```
1. Statement B1
2. post( bArrived )
3. wait( aArrived )
4. Statement B2
```

#### Rendezvous Solution 3 (working)

**Thread A**

```
1. Statement A1
2. wait( bArrived )
3. post( aArrived )
4. Statement A2
```

**Thread B**

```
1. Statement B1
2. post( bArrived )
3. wait( aArrived )
4. Statement B2
```

less efficient compare to solution 2

### Barrier

Given *n* threads, each of which knows that the total number of threads is *n*.

When the first *n* − 1 threads arrive, they should wait until the *n*th arrives.

- `count`: keep track of the number of threads that have reached the meeting point.

- `mutex`: a semaphore protecting that counter
- `barrier`: a semaphore will be the place where threads wait until the *n*th thread arrives.

#### Barrier Solution 1 (bad)

When the *n*th thread arrives, it unlocks the barrier and then may proceed.

**Thread K**

```
1. wait( mutex )
2. count++
3. post( mutex )
4. if count == n
5.     post( barrier )
6. end if
7. wait( barrier )
```

If there is more than one thread waiting at the barrier, the first thread will be unblocked when the *n*th thread posts on it. The other threads waiting are stuck, waiting for a post that never comes.

#### Barrier Solution 2 (bad)

The *n*th thread to arrive should post *n* − 1 times:

**Thread K**

```
1. wait( mutex )
2. count++
3. post( mutex )
4. if count == n
5.			for i from 1 to n 
6.						post(barrier)
7.			end for
8. end if
9. wait( barrier )
```

This is a solution that allows all of the n threads to proceed (none get stuck), but it is less than ideal. 

The n-th thread  is very likely the lowest priority thread (if it were high priority it would likely have run first) and therefore when it posts on the semaphore, the thread that has just been unblocked will be the next to run. Then the system switches back, at some later time, to the thread currently unblocking all the others. 

#### Barrier Solution 3 - turnstile (somehow working)

The *n*th thread to arrive should post for next, next thread should lock the next one

**Thread K**

```
1. wait( mutex )
2. count++
3. post( mutex )
4. if count == n
5.     post( barrier )
6. end if
7. wait( barrier )
8. post( barrier )
```

A turnstile pattern allows one thread at a time to proceed through, but can be locked to bar all threads from proceeding.

Initially the turnstile in the above example is locked, and the *n*th thread unlocks it and permits all *n* threads to go through.

In this solution we are reading the value of count, a shared variable, without the protection of a semaphore. (this is dangerous)

### Reusable Barrier

Decrement count after the rendezvous has taken place.

#### Reusable Barrier Solution 1()

**Thread** ***K***

```
 1. wait( mutex )
 2. count++
 3. if count == n
 4.     post( turnstile )
 5. end if
 6. post( mutex )
 7. wait( turnstile )
 8. post( turnstile )
 9. [critical point]
10. wait( mutex )
11. count--
12. if count == 0
13.     wait( turnstile )
14. end if
15. post( mutex )
```

Suppose one particular thread gets through the second mutex but is running in a loop and gets back through the first mutex again.

This would be like one thread being one “lap” ahead of the others.

#### two-phase barrier

**Thread** ***K***

```
 1. wait( mutex )
 2. count++
 3. if count == n
 4.     wait( turnstile2 )
 5.     post( turnstile1 )
 6. end if
 7. post( mutex )
 8. wait( turnstile1 )
 9. post( turnstile1 )
10. [critical point]
11. wait( mutex )
12. count--
13. if count == 0
14.     wait( turnstile1 )
15.     post( turnstile2 )
16. end if
17. post( mutex )
18. wait( turnstile2 )
19. post( turnstile2 )
```

From left to right, the seven steps of the diagram are [HZMG15]:

1. The threads arrive at the rendezvous (`wait( turnstile1 )`)
2. The nth thread arrives at the rendezvous.
3. That last thread unlocks the first turnstile and locks the second turnstile.
4. The threads pass through the first turnstile.
5. The nth thread passes through the first turnstile; it may not have been the last to arrive at the first turnstile. 
6. The thread that just arrived locks the first turnstile and unlocks the second.
7. The threads leave the rendezvous.